# Title:
[Analysis] High-Level API and Software Architecture Design

## Status/metadata:
Open — Issue created today

## [Business Summary]
As an **engineer**  
I want to have a clear understanding of the high-level API and software architecture  
So that I can start implementing the mapper API following clean architecture principles and establish patterns for future API development.

**Placeholder for technical analysis:**
- Design high-level software architecture following Clean Architecture principles
- Define API structure and layering approach
- Establish patterns for Azure integration and LLM orchestration

## [Acceptance Criteria]
- [ ] **Clean Architecture layers** defined (Interface, Application, Domain, Infrastructure)
- [ ] **API contract design** documented with request/response schemas
- [ ] **Domain entities and value objects** identified and modeled
- [ ] **Repository patterns** established for data access abstraction
- [ ] **Dependency injection strategy** designed for testability
- [ ] **Azure service integration** approach defined (OpenAI, Blob Storage)
- [ ] **Error handling and logging** patterns established
- [ ] **Architectural design** documented in Confluence
- [ ] **Technical follow-up stories** for implementation created

## [Expected Work]
- [ ] **Layer structure definition** with clear responsibilities
- [ ] **Domain modeling** for risk themes, taxonomy, and control mappings
- [ ] **API endpoint specification** for mapper functionality
- [ ] **Infrastructure abstraction design** for Azure services
- [ ] **Application service patterns** for business logic orchestration
- [ ] **Testing strategy** aligned with architecture layers

## [Technical Context]
- **Architecture Pattern**: Clean Architecture with domain-driven design
- **Framework**: FastAPI with Pydantic for validation
- **Platform**: Azure (OpenAI, Blob Storage, potential future services)
- **Language**: Python with type hints and strict validation
- **Key Principles**: Framework-free domain, dependency inversion, testability
- **Integration**: Azure OpenAI with JSON schema validation

## [Attachments / Mockups]
**Architecture Diagram**: Clean Architecture layers showing Interface → Application → Domain ← Infrastructure with dependency flow

**Folder Structure**: Organized by architectural layers with clear separation of concerns

---

# Title:
[Analysis] Unit Testing Strategy and Test Plan Design

## Status/metadata:
Open — Issue created today

## [Business Summary]
As a **developer**  
I want to have a comprehensive unit testing strategy and test plan  
So that I can ensure code quality, maintainability, and reliability across all layers of the mapper API with proper test coverage and mocking strategies.

**Placeholder for technical analysis:**
- Design unit testing strategy aligned with Clean Architecture layers
- Establish testing patterns for domain logic, application services, and infrastructure
- Define mocking strategies for Azure services and external dependencies

## [Acceptance Criteria]
- [ ] **Testing framework selection** and configuration (pytest, unittest)
- [ ] **Test structure organization** mirroring source code layers
- [ ] **Domain layer testing** strategy for entities and value objects
- [ ] **Application layer testing** with use case and service mocking
- [ ] **Infrastructure layer testing** with Azure service mocks
- [ ] **Interface layer testing** for API endpoint validation
- [ ] **Test coverage targets** defined (minimum 80% coverage)
- [ ] **Mocking strategies** documented for external dependencies
- [ ] **Test data management** approach for consistent test scenarios
- [ ] **CI/CD integration** for automated test execution
- [ ] **Testing documentation** created with examples and patterns

## [Expected Work]
- [ ] **Test framework setup** with pytest and required plugins
- [ ] **Mock strategy definition** for Azure OpenAI and Blob Storage
- [ ] **Test case templates** for each architectural layer
- [ ] **Domain entity testing** patterns and examples
- [ ] **Use case testing** with dependency injection mocks
- [ ] **API integration testing** approach
- [ ] **Test data fixtures** and factory patterns
- [ ] **Coverage reporting** configuration and thresholds

## [Technical Context]
- **Testing Framework**: pytest with asyncio support
- **Mocking**: unittest.mock, pytest-mock for Azure services
- **Coverage**: pytest-cov for coverage reporting
- **Test Structure**: Mirror src structure (tests/unit/domain/, tests/unit/application/, etc.)
- **Key Testing Areas**: LLM interactions, JSON schema validation, repository patterns
- **CI Integration**: Test execution in build pipeline with coverage gates

## [Attachments / Mockups]
**Test Structure**: tests/ directory organized by Clean Architecture layers

**Mock Patterns**: Examples for Azure OpenAI client, blob storage, and repository mocking


import pandas as pd
import matplotlib.pyplot as plt
import re

# Example dataframe
data = {
    "control_description": [
        "This control defines [WHO] is responsible.",
        "We need to ask What: happens in failure.",
        "WHEN the process fails, escalation is required.",
        "The report must explain (why) the exception occurred.",
        "Nothing mentioned here."
    ]
}
df = pd.DataFrame(data)

# Simplified regex patterns
patterns = {
    "Who": r"[\[\(\s]*who[\]\)\s:]*",
    "What": r"[\[\(\s]*what[\]\)\s:]*",
    "When": r"[\[\(\s]*when[\]\)\s:]*",
    "Where": r"[\[\(\s]*where[\]\)\s:]*",
    "Why": r"[\[\(\s]*why[\]\)\s:]*"
}

# Count occurrences
counts = {
    w: df["control_description"].str.contains(pat, flags=re.IGNORECASE, regex=True).sum()
    for w, pat in patterns.items()
}

# Convert to DataFrame for plotting
counts_df = pd.DataFrame(list(counts.items()), columns=["W", "Count"])

# Plot
counts_df.plot(kind="bar", x="W", y="Count", legend=False, rot=0)
plt.title("Presence of 5Ws in Control Descriptions")
plt.ylabel("Count")
plt.show()
